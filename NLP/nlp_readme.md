* These are datasets focus on NLP models. 
*  bbc, disater and scarasm don't contain readme file. 
* disater and scarasm datasets need to train with transfter learning methods to imporve accuarcy. Tokenize or embedded with transfer learning may increase accuary and decreasee loss. 
*  There is different NLP encode methods. I mostly encode with tokenized and embedding layers directed inside the model. Some otheres can try with padding first and input to embedding layers. The main different is input shapes and input layers. 
*  If you make with tokenized layers, model cannot be saved with h5 format in tensorflow.  

For beginner, 
*  For who want to do further study, there are many transfer learning for . 
*  For who want to train other dataset or test out, there are medical x-rays dataset, food vision dataset, objects vision dtasets. 