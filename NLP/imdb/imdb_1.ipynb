{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.11.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set into 60% and 40% to end up with 15,000 examples\n",
    "# for training, 10,000 examples for validation and 25,000 examples for testing.\n",
    "train_data, validation_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 13:46:36.096956: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([10]), TensorShape([10]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
    "train_examples_batch.shape , train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 50), dtype=float32, numpy=\n",
       "array([[ 0.5423195 , -0.0119017 ,  0.06337538,  0.06862972, -0.16776837,\n",
       "        -0.10581174,  0.16865303, -0.04998824, -0.31148055,  0.07910346,\n",
       "         0.15442263,  0.01488662,  0.03930153,  0.19772711, -0.12215476,\n",
       "        -0.04120981, -0.2704109 , -0.21922152,  0.26517662, -0.80739075,\n",
       "         0.25833532, -0.3100421 ,  0.28683215,  0.1943387 , -0.29036492,\n",
       "         0.03862849, -0.7844411 , -0.0479324 ,  0.4110299 , -0.36388892,\n",
       "        -0.58034706,  0.30269456,  0.3630897 , -0.15227164, -0.44391504,\n",
       "         0.19462997,  0.19528408,  0.05666234,  0.2890704 , -0.28468323,\n",
       "        -0.00531206,  0.0571938 , -0.3201318 , -0.04418665, -0.08550783,\n",
       "        -0.55847436, -0.23336391, -0.20782952, -0.03543064, -0.17533456],\n",
       "       [ 0.56338924, -0.12339553, -0.10862679,  0.7753425 , -0.07667089,\n",
       "        -0.15752277,  0.01872335, -0.08169781, -0.3521876 ,  0.4637341 ,\n",
       "        -0.08492756,  0.07166859, -0.00670817,  0.12686075, -0.19326553,\n",
       "        -0.52626437, -0.3295823 ,  0.14394785,  0.09043556, -0.5417555 ,\n",
       "         0.02468163, -0.15456742,  0.68333143,  0.09068331, -0.45327246,\n",
       "         0.23180096, -0.8615696 ,  0.34480393,  0.12838456, -0.58759046,\n",
       "        -0.4071231 ,  0.23061076,  0.48426893, -0.27128142, -0.5380916 ,\n",
       "         0.47016326,  0.22572741, -0.00830663,  0.2846242 , -0.304985  ,\n",
       "         0.04400365,  0.25025874,  0.14867121,  0.40717036, -0.15422426,\n",
       "        -0.06878027, -0.40825695, -0.3149215 ,  0.09283665, -0.20183425],\n",
       "       [ 0.7456154 ,  0.21256861,  0.14400336,  0.5233862 ,  0.11032254,\n",
       "         0.00902788, -0.3667802 , -0.08938274, -0.24165542,  0.33384594,\n",
       "        -0.11194605, -0.01460047, -0.0071645 ,  0.19562712,  0.00685216,\n",
       "        -0.24886718, -0.42796347,  0.18620004, -0.05241098, -0.66462487,\n",
       "         0.13449019, -0.22205497,  0.08633006,  0.43685386,  0.2972681 ,\n",
       "         0.36140734, -0.7196889 ,  0.05291241, -0.14316116, -0.1573394 ,\n",
       "        -0.15056328, -0.05988009, -0.08178931, -0.15569411, -0.09303783,\n",
       "        -0.18971172,  0.07620788, -0.02541647, -0.27134508, -0.3392682 ,\n",
       "        -0.10296468, -0.27275252, -0.34078008,  0.20083304, -0.26644835,\n",
       "         0.00655449, -0.05141488, -0.04261917, -0.45413622,  0.20023568]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "hub_layer(train_examples_batch[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_2 (KerasLayer)  (None, 50)                48190600  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,191,121\n",
      "Trainable params: 48,191,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 19s 603ms/step - loss: 0.6965 - accuracy: 0.5166 - val_loss: 0.6304 - val_accuracy: 0.5588\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 17s 578ms/step - loss: 0.5787 - accuracy: 0.6383 - val_loss: 0.5539 - val_accuracy: 0.6789\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 17s 582ms/step - loss: 0.4817 - accuracy: 0.7667 - val_loss: 0.4729 - val_accuracy: 0.7836\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 17s 572ms/step - loss: 0.3771 - accuracy: 0.8507 - val_loss: 0.3924 - val_accuracy: 0.8252\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 18s 591ms/step - loss: 0.2771 - accuracy: 0.8995 - val_loss: 0.3395 - val_accuracy: 0.8481\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2048 - accuracy: 0.9315 - val_loss: 0.3144 - val_accuracy: 0.8645\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 18s 605ms/step - loss: 0.1530 - accuracy: 0.9551 - val_loss: 0.3036 - val_accuracy: 0.8686\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.1151 - accuracy: 0.9698 - val_loss: 0.3023 - val_accuracy: 0.8671\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 18s 610ms/step - loss: 0.0867 - accuracy: 0.9802 - val_loss: 0.3088 - val_accuracy: 0.8634\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 18s 591ms/step - loss: 0.0658 - accuracy: 0.9867 - val_loss: 0.3118 - val_accuracy: 0.8684\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1,))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data.shuffle(10000).batch(512),\n",
    "                    epochs=10,\n",
    "                    validation_data=validation_data.batch(512),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 - 3s - loss: 0.3357 - accuracy: 0.8519 - 3s/epoch - 62ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data.batch(512), verbose=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_tfdataset(tfdataset, batched=False):\n",
    "\n",
    "    features = list(map(lambda x: x[0], tfdataset)) # Get labels \n",
    "\n",
    "    if not batched:\n",
    "        return tf.stack(features, axis=0)\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_labels_from_tfdataset(tfdataset, batched=False):\n",
    "\n",
    "    labels = list(map(lambda x: x[1], tfdataset)) # Get labels \n",
    "\n",
    "    if not batched:\n",
    "        return tf.stack(labels, axis=0)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([15000]), TensorShape([15000]), 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = get_labels_from_tfdataset(train_data)\n",
    "features = get_features_from_tfdataset(train_data)\n",
    "labels.shape, features.shape , features.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([25000]), TensorShape([25000]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature = get_features_from_tfdataset(test_data)\n",
    "test_labels = get_labels_from_tfdataset(test_data)\n",
    "test_feature.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10000]), TensorShape([10000]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_features = get_features_from_tfdataset(validation_data)\n",
    "valid_label = get_labels_from_tfdataset(validation_data)\n",
    "valid_features.shape, valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 15s 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.3208473 ],\n",
       "       [ 0.5171427 ],\n",
       "       [ 4.4492545 ],\n",
       "       ...,\n",
       "       [-8.56695   ],\n",
       "       [ 2.4473455 ],\n",
       "       [ 0.49425808]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_preds_probs = model.predict(valid_features)\n",
    "result_preds_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 1), TensorShape([10000]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_preds_probs.shape , valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000,), dtype=float32, numpy=array([ 1.,  1.,  4., ..., -9.,  2.,  0.], dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_preds = tf.squeeze(tf.round(result_preds_probs))\n",
    "result_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_results(y_true, y_pred):\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and f1 score using \"weighted average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\", zero_division= 1)\n",
    "    model_results = {\"accuracy\": model_accuracy,\n",
    "                      \"precision\": model_precision,\n",
    "                      \"recall\": model_recall,\n",
    "                      \"f1\": model_f1}\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 8.3,\n",
       " 'precision': 0.5918972273929656,\n",
       " 'recall': 0.083,\n",
       " 'f1': 0.1455836900312579}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = calculate_accuracy_results( \n",
    "    y_true= valid_label,\n",
    "    y_pred = result_preds)\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with another methods. Building own tokenized layers and embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233.5422"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long is each sentence on average?\n",
    "sent_lens = [len(sentence.split()) for sentence in features.numpy()]\n",
    "avg_sent_len = np.mean(sent_lens)\n",
    "avg_sent_len # return average sentence length (in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sent_lens, bins=7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long of a sentence covers 95% of the lengths?\n",
    "output_seq_len = int(np.percentile(sent_lens, 95))\n",
    "output_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.',\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.'>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[1].numpy() ,features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "max_vocab = 5000  # Maximum vocab size.\n",
    "max_seq_len = 600  # Sequence length to pad the outputs to.\n",
    "\n",
    "# Create the layer.\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_vocab,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_seq_len)\n",
    "\n",
    "# Now that the vocab layer has been created, call `adapt` on the\n",
    "# text-only dataset to create the vocabulary. You don't have to batch,\n",
    "# but for large datasets this means we're not keeping spare copies of\n",
    "# the dataset.\n",
    "vectorize_layer.adapt(features)\n",
    "\n",
    "embedding_layers = layers.Embedding(input_dim=max_vocab,\n",
    "                                     output_dim=5,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length = max_seq_len,\n",
    "                                     name=\"embedding_layers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "b'This is one of my favorites along with the Mariette Hartley and Robert Lansing \"Sandy\" and the Agnes Moorhead-and-the-tiny-spacemen episodes.<br /><br />It is an important take, from mid-1961, on the long Cold War that the U.S. was then embroiled in. The beaten-down city-scene, the near-starving characters\\' sparse dialog, their threadbare uniforms, and the minimal action \"says\" it all: the absurdity of an on-going conflict that threatens to destroy human life, modern civilization, and all that is sweet and redeeming about it.<br /><br />It is a \"fable\" because it was made in a time in which, had events turned out differently, such as the second Berlin Crisis (Spring 1961) and the subsequent Cuban Missile Crisis (Oct. 1962), it would have actually been a reasonable representation of one of the U.S.\\'s major cities, ruined and replete with a few miserable survivors. I also see it as a \"fable\" because it is not only a cautionary tale, but because it is the most redemptive of all our popular myths: it is a love story, set in an impossible situation, and involving two highly mismatched lovers.'      \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 600), dtype=int64, numpy=\n",
       "array([[  11,    7,   29,    5,   54, 2526,  354,   17,    2,    1,    1,\n",
       "           3,  655,    1,    1,    3,    2,    1,    1,    1,   13,    9,\n",
       "           7,   34,  671,  186,   36,    1,   21,    2,  204, 1083,  332,\n",
       "          12,    2,  170,   14,   91,    1,    8,    2,    1,    1,    2,\n",
       "           1,  103,    1,  779,   66,    1,    1,    3,    2, 3883,  218,\n",
       "         526,    9,   32,    2,    1,    5,   34,    1, 1964,   12,    1,\n",
       "           6, 2240,  402,  118,  732, 4169,    3,   32,   12,    7, 1071,\n",
       "           3, 1505,   43,  597,   13,    9,    7,    4,    1,   81,    9,\n",
       "          14,   93,    8,    4,   60,    8,   62,   65,  653,  662,   46,\n",
       "           1,  136,   15,    2,  320,    1, 3574, 3177,    1,    3,    2,\n",
       "        3800,    1,    1, 3574,    1,    1,    9,   56,   26,  155,   75,\n",
       "           4, 3806,    1,    5,   29,    5,    2,    1,  659,    1, 2127,\n",
       "           3,    1,   17,    4,  167, 4365, 4247,   10,   76,   64,    9,\n",
       "          15,    4,    1,   81,    9,    7,   22,   61,    4,    1,  763,\n",
       "          19,   81,    9,    7,    2,   88,    1,    5,   32,  254, 1068,\n",
       "           1,    9,    7,    4,  116,   68,  276,    8,   34, 1166,  892,\n",
       "           3, 1131,  105,  543,    1, 1798,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_sentence = random.choice(features)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nVectorized version:\")\n",
    "vectorize_layer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(15000, 600), dtype=int64, numpy=\n",
       "array([[  11,   14,   34, ...,    0,    0,    0],\n",
       "       [  10,   26,   75, ...,    0,    0,    0],\n",
       "       [3814,    1,    2, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  10,  205,   11, ...,    0,    0,    0],\n",
       "       [  95, 2925,    1, ...,    0,    0,    0],\n",
       "       [ 204,  352,    1, ...,    0,    0,    0]])>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = vectorize_layer(features)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(15000, 600, 5), dtype=float32, numpy=\n",
       "array([[[ 4.09096517e-02,  3.17290910e-02, -2.70222072e-02,\n",
       "         -4.17363867e-02,  1.75849460e-02],\n",
       "        [ 1.38682835e-02,  1.70120858e-02,  2.52556466e-02,\n",
       "          3.44460346e-02,  3.82332094e-02],\n",
       "        [-2.66459230e-02,  3.96789238e-03,  2.98628099e-02,\n",
       "          2.27715708e-02, -6.71520829e-05],\n",
       "        ...,\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03],\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03],\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03]],\n",
       "\n",
       "       [[-8.98679346e-03, -4.90548499e-02, -9.79293510e-03,\n",
       "          1.07310042e-02, -1.84064135e-02],\n",
       "        [ 1.90337785e-02,  4.12664674e-02,  2.66545527e-02,\n",
       "         -1.61222927e-02, -2.55167373e-02],\n",
       "        [ 1.35502256e-02,  4.02995609e-02, -2.83284541e-02,\n",
       "          4.63646390e-02, -4.72396873e-02],\n",
       "        ...,\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03],\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03],\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03]],\n",
       "\n",
       "       [[ 4.62741368e-02,  2.21883133e-03,  1.07879862e-02,\n",
       "         -4.61982749e-02, -2.59272344e-02],\n",
       "        [-2.05407143e-02, -2.81718262e-02, -3.26162353e-02,\n",
       "          2.35539936e-02, -5.89934736e-03],\n",
       "        [-1.86437741e-02, -3.66886258e-02, -2.41354108e-02,\n",
       "         -2.06746943e-02, -3.38673145e-02],\n",
       "        ...,\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03],\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03],\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-8.98679346e-03, -4.90548499e-02, -9.79293510e-03,\n",
       "          1.07310042e-02, -1.84064135e-02],\n",
       "        [ 4.31589223e-02, -3.91000994e-02,  1.44748725e-02,\n",
       "          4.35326584e-02,  3.17251422e-02],\n",
       "        [ 4.09096517e-02,  3.17290910e-02, -2.70222072e-02,\n",
       "         -4.17363867e-02,  1.75849460e-02],\n",
       "        ...,\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03],\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03],\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03]],\n",
       "\n",
       "       [[-3.18623185e-02, -3.05918455e-02, -3.79448049e-02,\n",
       "          3.07617895e-02, -3.00541651e-02],\n",
       "        [ 2.42867805e-02,  4.60146777e-02,  4.13842835e-02,\n",
       "         -1.58347860e-02, -1.55845881e-02],\n",
       "        [-2.05407143e-02, -2.81718262e-02, -3.26162353e-02,\n",
       "          2.35539936e-02, -5.89934736e-03],\n",
       "        ...,\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03],\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03],\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03]],\n",
       "\n",
       "       [[ 4.79402058e-02, -4.21734825e-02,  3.45272161e-02,\n",
       "         -1.10412464e-02,  2.87217386e-02],\n",
       "        [ 8.38623196e-03,  1.99544169e-02, -2.60973219e-02,\n",
       "          2.34103538e-02,  3.84918340e-02],\n",
       "        [-2.05407143e-02, -2.81718262e-02, -3.26162353e-02,\n",
       "          2.35539936e-02, -5.89934736e-03],\n",
       "        ...,\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03],\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03],\n",
       "        [-4.06331643e-02, -5.31888008e-03,  7.92244822e-03,\n",
       "          3.69123369e-03, -2.63007730e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_emb = embedding_layers(test)\n",
    "test_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_1 (TextV  (None, 600)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_layers (Embedding  (None, 600, 5)           25000     \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 600, 32)           192       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 600, 16)           528       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 600, 1)            17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,737\n",
      "Trainable params: 25,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = tf.keras.Sequential()\n",
    "model_2.add(tf.keras.layers.Input(shape=(1,), dtype=\"string\", name=\"Input\"))\n",
    "model_2.add(vectorize_layer)\n",
    "model_2.add(embedding_layers)\n",
    "model_2.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model_2.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model_2.add(tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid))\n",
    "\n",
    "model_2.summary()\n",
    "\n",
    "model_2.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss = tf.keras.losses.binary_crossentropy,\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 600)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_layers (Embedding  (None, 600, 5)           25000     \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3000)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                96032     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,065\n",
      "Trainable params: 121,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model with functional API\n",
    "inputs = layers.Input(shape=(1,), dtype= tf.string)\n",
    "x = vectorize_layer(inputs)\n",
    "x = embedding_layers(x)\n",
    "#x = layers.Conv1D(16,5,padding=\"same\",activation=\"relu\")(x)\n",
    "#x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=tf.keras.activations.sigmoid)(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.00075),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 6s 10ms/step - loss: 0.5738 - accuracy: 0.6654 - val_loss: 0.3659 - val_accuracy: 0.8423\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2660 - accuracy: 0.8962 - val_loss: 0.3437 - val_accuracy: 0.8539\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1645 - accuracy: 0.9411 - val_loss: 0.3750 - val_accuracy: 0.8506\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1022 - accuracy: 0.9667 - val_loss: 0.4173 - val_accuracy: 0.8461\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0564 - accuracy: 0.9853 - val_loss: 0.4654 - val_accuracy: 0.8497\n"
     ]
    }
   ],
   "source": [
    "history_3 = model_3.fit(features,\n",
    "                    labels,\n",
    "                    epochs=5,\n",
    "                    validation_data=[valid_features,valid_label],\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 4ms/step - loss: 0.4737 - accuracy: 0.8440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47373166680336, 0.8440399765968323]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(test_feature,test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encode labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "train_labels_one_hot = one_hot_encoder.fit_transform(labels.numpy().reshape(-1, 1))\n",
    "val_labels_one_hot = one_hot_encoder.transform(valid_label.numpy().reshape(-1, 1))\n",
    "test_labels_one_hot = one_hot_encoder.transform(test_labels.numpy().reshape(-1, 1))\n",
    "\n",
    "# Check what training labels look like\n",
    "train_labels_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract labels (\"target\" columns) and encode them into integers \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(labels.numpy())\n",
    "val_labels_encoded = label_encoder.transform(valid_label.numpy())\n",
    "test_labels_encoded = label_encoder.transform(test_labels.numpy())\n",
    "\n",
    "# Check what training labels look like\n",
    "train_labels_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 10000, 25000)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = features.numpy().tolist()\n",
    "val_sentences = valid_features.numpy().tolist()\n",
    "test_sentences = test_feature.numpy().tolist()\n",
    "len(train_sentences), len(val_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline\n",
    "model_0 = Pipeline([\n",
    "  (\"tf-idf\", TfidfVectorizer()),\n",
    "  (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(X=train_sentences, \n",
    "            y=train_labels_encoded);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8589"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate baseline on validation dataset\n",
    "model_0.score(X=val_sentences,\n",
    "              y=val_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = calculate_accuracy_results(val_labels_encoded,baseline_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9835575e-01],\n",
       "       [4.7553548e-01],\n",
       "       [9.9736762e-01],\n",
       "       ...,\n",
       "       [6.9005197e-05],\n",
       "       [9.8883671e-01],\n",
       "       [7.3503774e-01]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_preds_probs = model_3.predict(valid_features)\n",
    "cnn_preds_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000,), dtype=float32, numpy=array([1., 0., 1., ..., 0., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_preds = tf.squeeze(tf.round(cnn_preds_probs))\n",
    "cnn_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000,), dtype=int64, numpy=array([1, 1, 1, ..., 0, 0, 1])>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 84.97,\n",
       " 'precision': 0.8497343949775799,\n",
       " 'recall': 0.8497,\n",
       " 'f1': 0.8497014864748634}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_results = calculate_accuracy_results(cnn_preds,valid_label)\n",
    "cnn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 85.89,\n",
       " 'precision': 0.8599883576684628,\n",
       " 'recall': 0.8589,\n",
       " 'f1': 0.8588024812202042}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_results(baseline_results, new_model_results):\n",
    "  for key, value in baseline_results.items():\n",
    "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 85.89, New accuracy: 84.97, Difference: -0.92\n",
      "Baseline precision: 0.86, New precision: 0.85, Difference: -0.01\n",
      "Baseline recall: 0.86, New recall: 0.85, Difference: -0.01\n",
      "Baseline f1: 0.86, New f1: 0.85, Difference: -0.01\n"
     ]
    }
   ],
   "source": [
    "compare_two_results(baseline_results,cnn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 600)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_layers (Embedding  (None, 600, 5)           25000     \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 600, 16)           416       \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 16)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,993\n",
      "Trainable params: 25,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model with functional API\n",
    "inputs = layers.Input(shape=(1,), dtype= tf.string)\n",
    "x = vectorize_layer(inputs)\n",
    "x = embedding_layers(x)\n",
    "x = layers.Conv1D(16,5,padding=\"same\",activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=tf.keras.activations.sigmoid)(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 7s 13ms/step - loss: 0.4436 - accuracy: 0.8233 - val_loss: 0.3731 - val_accuracy: 0.8356\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.2892 - accuracy: 0.8823 - val_loss: 0.3593 - val_accuracy: 0.8455\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.2222 - accuracy: 0.9155 - val_loss: 0.3672 - val_accuracy: 0.8452\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.1716 - accuracy: 0.9393 - val_loss: 0.3766 - val_accuracy: 0.8508\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.1300 - accuracy: 0.9571 - val_loss: 0.4128 - val_accuracy: 0.8462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3baf5dceb0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_4.fit(features,\n",
    "            labels,\n",
    "            epochs=5,\n",
    "            validation_data=[valid_features,valid_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 6ms/step - loss: 0.4155 - accuracy: 0.8461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41551241278648376, 0.8460800051689148]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.evaluate(test_feature,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_preds_probs = model_4.predict(val_sentences)\n",
    "\n",
    "model_4_preds_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_preds = tf.squeeze(tf.round(model_4_preds_probs))\n",
    "model_4_preds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_results = calculate_accuracy_results(y_true = val_labels_encoded,\n",
    "                                             y_pred = model_4_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 84.97,\n",
       " 'precision': 0.8497343949775799,\n",
       " 'recall': 0.8497,\n",
       " 'f1': 0.8497014864748634}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_results #model_3_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 85.89,\n",
       " 'precision': 0.8599883576684628,\n",
       " 'recall': 0.8589,\n",
       " 'f1': 0.8588024812202042}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 84.61999999999999,\n",
       " 'precision': 0.8476222773559714,\n",
       " 'recall': 0.8462,\n",
       " 'f1': 0.8460304309532602}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 8.3,\n",
       " 'precision': 0.5918972273929656,\n",
       " 'recall': 0.083,\n",
       " 'f1': 0.1455836900312579}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results # model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fcd31d782b6120f2993dc67dd18a19e8000177e7f61203562e17b1bd19b8f69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
